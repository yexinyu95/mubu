- 估计量的定义
	- （任意一个统计量就是一个估计量），
- 求估计量的方法
	- 矩估计
	  collapsed:: true
		- 求解
		  collapsed:: true
			- 方法为令k阶样本矩 = k阶总体矩，
				- 一般k个参数需要联立k个方程，
				- 理论上，求解矩估计无需总体分布，
			- 有时一阶矩可能难以求解，此时应使用高阶矩来辅助计算，
			- 理论上，对于限制范围的\theta，矩估计的求解方法不变，
			- 矩估计的理论基础为大数定律，
		- 性质
		  collapsed:: true
			- 不唯一性
				- 矩估计不唯一，有时参数可能对应多个样本矩的值，如泊松分布的均值和方差，
			- 不变性
				- 若函数g(x)为连续函数，统计量T为参数\theta的矩估计，则g(T)为g(\theta)的矩估计，
		- 矩匹配
		  collapsed:: true
			- 假设Y = g(X)，X的分布和函数g(X)已知，但Y的准确分布难以求得，
			- 可以通过X的分布估计Y的近似分布，并求解对应的总体矩EY；再通过E[g(X)]求解Y的样本矩，
			- 最后分析样本矩与总体矩，得出Y的参数的一个估计，
		- Satterthwaite近似（卡方分布）
		  collapsed:: true
			- 总体
			  collapsed:: true
				- $X_{1}, X_{2},..., X_{n}$为独立的卡方随机变量，其自由度分别为r_{i}，
				- 设$Y = \sum\limits_{i =1}^{n} a_i{X}_{i}$，其中a_{i}为已知常数，
				  id:: 62b1405b-fea5-4c00-9122-7aaed720f97d
				- 则Y也为随机变量，但Y的准确分布较难求得，
			- 估计方法
			  collapsed:: true
				- 设Y的近似分布为$\dfrac{{\chi}^{2}_{v}}{v}$，
				- $EY = E(\sum\limits_{i =1}^{n} a_i{X}_{i}) = \sum\limits_{i =1}^{n} {a}_{i}E({X}_{i}) = \sum\limits_{i =1}^{n} {a}_{i}{r}_{i}$，
				- $E(\dfrac{{\chi}^{2}_{v}}{v}) = 1$，
				- 由矩匹配方法，可设$\sum\limits_{i =1}^{n} {a}_{i}{r}_{i} = 1$，
				- （利用二阶矩匹配）
			- 估计分布
			  collapsed:: true
				- $Y \sim \dfrac{{\chi}^{2}_{v}}{v}$，
				- 设*X_{i}*为总体，则参数v的估计值为$\dfrac{{(\sum{a}_{i}{X}_{i})}^{2}}{\sum\dfrac{{a}_{i}^{2}}{{r}_{i}}{X}_{i}^{2}}$，
	- 极大似然估计
	  collapsed:: true
		- 似然函数
			- 设样本的*联合分布*$f_{\vec{X}}(x_{1}, x_{2},..., x_{n}; {\theta}_{1}, {\theta}_{2},..., {\theta}_{m})$，
			- 对确定的样本值$\vec{X} = \vec{x}$，称*关于参数θ*的函数$L_{\vec{\theta}}({\theta}_{1}, {\theta}_{2},..., {\theta}_{m}; x_{1}, x_{2},..., x_{n})$为似然函数，
		- 似然函数的求解
			- 样本联合分布
				- 似然样本的定义为样本的*联合分布*，应注意具体问题具体分析，
				- n个独立同分布样本（一般情况）
				  collapsed:: true
					- 由独立同分布随机变量的性质，可知，
					- 样本联合分布$f_{\vec{X}}(x_{1}, x_{2},..., x_{n}; {\theta}_{1}, {\theta}_{2},..., {\theta}_{m}) = \prod \limits _{i = 1}^{n} f_{X_{i}}(x_{i}; {\theta}_{1}, {\theta}_{2},..., {\theta}_{m})$，
				- 样本之间不独立
				  collapsed:: true
					- 应根据其他信息，求解联合分布$f_{\vec{X}}(x_{1}, x_{2},..., x_{n}; {\theta}_{1}, {\theta}_{2},..., {\theta}_{m})$，
				- 样本来自不同分布的总体
				  collapsed:: true
					- 应根据总体的不同情况，分别写出对应的样本联合分布，
					- 例如，若总体$X \sim \begin{cases}  f_{X}(x) & case1 \\ g_{X}(x) & case2 \end{cases}$，样本为独立同分布，
					- 则样本联合分布需要对应写为$\vec{X} \sim \begin{cases}  f_{\vec{X}}(\vec{x}) = \prod f_{X}(x) & case1 \\ g_{\vec{X}}(\vec{x}) = \prod g_{X}(x) & case2 \end{cases}$，
					- 然后，依据样本的取值可能，对似然函数分段讨论，
				- 只有几个样本
				  collapsed:: true
					- 应寻找剩余样本的信息，并以概率的形式写入似然函数，
					- 例如，若观测到$X_{1}, X_{2},..., X_{m}$和部分剩余样本信息$X_{m + i} \geq t$，
					- 则似然函数应写为$f_{\vec{X}}(\vec{x}) = \prod \limits _{i = 1}^{m}f_{X_{i}}(x) \cdot \prod \limits _{j = m + 1}^{n}[P(X_{j} \geq t)] = {[f_{X}(x)]}^{m} \cdot {[1 - F_{X}{(t)}]}^{n - m}$，
		- 似然函数定理
		  collapsed:: true
			- 在正则条件下，似然函数在参数的真值处渐近取得最大值，
		- （似然原理）
		  collapsed:: true
			- 若对两个不同的样本点$\vec{X} = \vec{x_1}$和$\vec{X} = \vec{x_2}$，似然比$\dfrac{L(\theta|\vec{x_1})}{L(\theta|\vec{x_2})}$为不依赖于参数\theta的某数值$C(\vec{x_1}, \vec{x_2})$，
			- 则由$\vec{x_1}, \vec{x_2}$所做的关于参数\theta的推断应该相同，
		- 极值的求解
		  collapsed:: true
			- 定义：使L(θ)最大化的θ的取值为mle，
			- 基本方法
			  collapsed:: true
				- 微分法
				- 分析似然函数性质（单调性）
				- 离散分布的极值
			- 技巧
			  collapsed:: true
				- 由于pdf总为正值，所以一般使用对数似然函数求解，可以简化计算，
				- 对于约束值域的mle，应综合似然函数，分析似然函数在限制区域上的性质，
				- 画图辅助分析
				- 特定参数的mle的求解可能不会用到所有样本，
				- 似然函数可能不需要每个样本的准确分布，而是只需要（充分）统计量的分布，
			- （离散情况）
			  collapsed:: true
				- 离散分布下，极值的等价条件为$\dfrac{L(\theta|x)}{L(\theta - 1)|x} \geq 1$且$\dfrac{L(\theta|x)}{L(\theta + 1)|x} > 1$，
			- mle极值的验证（逐次极大化）
		- mle的性质
		  collapsed:: true
			- 不变性（参数的函数的估计）
			- 充分性
			- 相合性、渐近正态性
		- （EM算法）
		- （刀切法）
- 估计量的评价
	- 分布的信息
	  collapsed:: true
		- 得分函数 S(\theta)
		  collapsed:: true
			- 由pdf定义的关于参数θ的函数，一般为随机变量，
			- 定义：$S(\theta) = \dfrac{\partial \ln f} {\partial \theta}$，
				- 多个参数时为向量$(\dfrac{\partial \ln f} {\partial \theta_1}, \dfrac{\partial \ln f} {\partial \theta_2}, \dfrac{\partial \ln f} {\partial \theta_3}...)$，其维度与*参数θ的个数*有关，而与*随机变量个数*无关，
				- f为所求统计量的密度函数（pdf），不同的统计量由于其pdf不同，所以对应的得分函数也不同，
			- 一般得分函数中既有参数也有随机变量，所以得分函数不是常数而是随机变量，但可能不是统计量，
			- 由于得分函数为随机变量，所以得分函数具有数字特征——ES = 0，Var S = I(\theta)，
		- 费舍尔信息量 I(\theta)
			- 由pdf定义的关于参数θ的函数，一般为常量，
			- 定义：$I(\theta) = Var(\dfrac{\partial \ln f} {\partial \theta})$，
			- 计算方式：$E[(\dfrac{\partial \ln f} {\partial \theta})^2], -E(\dfrac{\partial ^2 \ln f} {\partial \theta^2})$；
			  collapsed:: true
				- 一般求高阶偏导更容易计算，
				- 虽然费舍尔信息量为参数的函数，与随机变量的形式无关，但求费舍尔信息量的过程为求解期望，因此需要分析随机变量的具体形式，
				- （计算方式的来源：得分函数的期望ES = 0，对积分式两端对参数θ求导，即可得到上述等式），
			- 计算技巧
				- 若总体有分布f和信息量I(θ)，则由n个独立同分布样本组成的联合分布L的信息量为nI(θ)，
				- 样本独立但不同分布时，也有$I_L(\theta) = \sum\limits_ {i =1} ^n I_{X_i}(\theta)$ ，
				- θ的充分统计量的pdf的信息量与样本联合分布L的信息量相同，θ的辅助统计量的pdf的信息量为0，
				- 对于位置族分布X = e + θ，
					- X的pdf关于位置族参数θ的信息量为θ的常函数；
					- e的pdf关于θ的信息量为0，
		- 费舍尔信息矩阵
		  collapsed:: true
			- 由分布函数定义的n阶矩阵，其阶数为参数的个数，与随机变量个数无关，
			- 其中的第i行，第j个元素的信息量为$I_{ij} = -E(\dfrac{\partial ^2 \ln f} {\partial \theta _i \partial \theta _j})$，
	- 估计量的性质
	  collapsed:: true
		- 数字特征的计算
		  collapsed:: true
			- 估计量的分布
			- 数字特征的性质
		- 无偏性
		- 相合性
		- 有效性
	- 损失函数
	  collapsed:: true
		- 决策函数（统计量）
		  collapsed:: true
			- 称\delta(X)为决策函数，
			- 一般而言，决策函数为统计量的函数，因此也为统计量，
		- 损失函数
		  collapsed:: true
			- 称关于决策函数\delta(X)和总体参数\theta的函数为损失函数，
			- 一般记为L(\theta, \delta(X))，
		- 风险函数
			- 称损失函数的数学期望为风险函数，一般记为R(\theta)，
			- 即$R(\theta) = E[L(\theta, \delta(X))]$，
			- 常用损失函数
				- 均方误差损失函数（MSE）
					- $L(\theta, \delta(X)) = {(\delta(X) - \theta)}^{2}$，
					- 对应的风险函数为$E[{(\delta(X) - \theta)}^{2}] = \operatorname{Var}(\delta(X)) + {[E\delta(X) - \theta]}^{2}$，
					- （有时也将${[E\delta(X) - \theta]}$写为Bias(\delta(X))，
					- 对于无偏估计量，其均方误差就是估计量的方差，
				- 绝对值损失函数
					- $L(\theta, \delta(X)) = |\delta(X) - \theta)|$，
					- 一般认为绝对值在数学上较难处理，所以均方误差使用的较多，
		- 极小化极大值原理
		  collapsed:: true
			- 对所有其他决策函数\delta，
			- 在\theta \in \Omega上，决策函数\delta_{0}使其对应的风险函数R(\theta)的极大值极小化（即并非所有函数值都是最小的），
	- C-R不等式
	  collapsed:: true
		- 定义
		  collapsed:: true
			- 统计量W(X)的方差$Var(W) ≥\dfrac{[(E_\theta W)_\theta']^2} {I(\theta)}$；
			- I(θ)由W基于的样本的联合分布L计算得到，因为W的期望可以由$\int W(x)L(x) dx$算得，
			- 统计量的有效性
		- 技巧
		  collapsed:: true
			- 若W为参数θ的无偏估计，则$EW = θ，(EW)' = 1$；此时C-R下界为$\frac{1}{I(θ)}$，
			- 若W为参数的函数g(θ)的无偏估计，则$EW = g(θ)，(EW)' = g'(θ)$；此时C-R下界为$[g'(θ)]^2/I(θ)$，不需要计算I[g(θ)]，
			- 若W为基于n个独立同分布样本的统计量，则其信息量为总体的n倍，即C-R下界为$\frac{1}{nI(θ)}$，
		- 不等式适用范围
		  collapsed:: true
			- 正则条件：可以在积分号下微分，方差有限等，
			- 一般支集依赖于θ时（如均匀分布），不等式不适用，
		- （定理：达到下界的条件）
- 无偏估计
	- 最佳无偏估计量（UMVUE）
		- 引入
		  collapsed:: true
			- 由于对估计量的要求较为宽泛，所以在所有估计量的集合中求解“最佳”的估计量较为困难，即难以找到合适的标准，
			- 因此，一种标准为，将估计量限制在无偏的范围内，再利用损失函数来分析这些无偏估计量的最优性，
		- 定义
		  collapsed:: true
			- 若估计量W为无偏估计，即EW = \theta，且对于所有其它的无偏估计量W'，总有VarW ≤ VarW'；则称W为参数\theta的最小方差无偏估计量（MVUE），
			- （将上述定义中的参数\theta换为参数的函数g(\theta)，此时的W称为一致最小方差无偏估计量（UMVUE）），
	- 定理
	  collapsed:: true
		- 0的无偏估计
		  collapsed:: true
			- 参数g(\theta)的无偏估计量W为最佳无偏估计量的充分必要条件为W与0的所有无偏估计都不相关，
			- 实际求解时，应先找出基于给定分布族的0的无偏估计，即使$E_{\theta}(U) = 0$的统计量U，
			- 基本求解方法为利用定义$E_{\theta}(U) = \int_{S_{X}}f_{U}(X)dx = 0$，寻找可能的函数U(X)，
			- 然后根据统计量U和W的形式求解协方差Cov(U, W)，
			- 若X为完备族，按完备族的定义，X的唯一0无偏估计就是数字0本身，
			- 对于非完备族，寻找所有0的无偏估计并不容易，因此该定理主要用于反证统计量W不是最佳无偏估计，
		- R-B定理
		  collapsed:: true
			- 若W为g(\theta)的无偏估计量，T为参数\theta的充分统计量，
			- 定义条件期望E(W | T) = h(T)，
			- 则h(T)为一个比W更优（方差较小）的无偏估计量，
		- Lehmann-Scheffe定理
		  collapsed:: true
			- 若统计量T为充分统计量，T的分布族为完备族，且存在T的函数h(T)为参数g(\theta)的无偏估计，
			- 则统计量h(T)为参数g(\theta)的唯一最优无偏估计（UMVUE），
	- 求解
		- 基本思路为寻找L-S定理所需要的条件，即充分性和无偏性，
		- 比较法
		  collapsed:: true
			- 基于充分统计量T，
			  collapsed:: true
				- （判断统计量T是否为完备族），
				- 求解充分统计量T的期望ET，
				- 比较ET与需要求解的参数\theta（或参数的函数h(\theta)），
				- 若可写为$ET = f[h(\theta)]$，且f为一一对应函数，
				- 则可解得$E[f^{-1}(T)] = f^{-1}(f[h(\theta)]) = h(\theta)$，
				- 因此，由L-S定理可知$f^{-1}(T)$为h(\theta)的UMVUE，
			- 基于最大似然估计量W，
			  collapsed:: true
				- （判断统计量T是否为完备族），
				- （一般mle估计量W为充分统计量T的函数，若W不是T的函数，则应基于充分统计量T寻找），
				- 由mle的不变性，可知需要求解的参数的函数h(\theta)的mle为h(W)，
				- 求解h(W)的期望E[h(W)]，
				- 比较E[h(W)]与需要求解的参数的函数h(\theta)，
				- 同上，若可写为$E[h(W)] = f[h(\theta)]$，且f为一一对应函数，
				- 则可解得$E[f^{-1}(h(W))] = f^{-1}(f[h(\theta)]) = h(\theta)$，
				- 因此，由L-S定理可知$f^{-1}(h(W))$为h(\theta)的UMVUE，
		- R-B定理法
		  collapsed:: true
			- 充分统计量T
			  collapsed:: true
				- R-B定理的基本思路为，基于无偏估计量W的*充分统计量T的函数*为UMVUE，
				- 因此，应先依据分布族的形式，寻找充分统计量T，
				- 然后应求出T的分布（数字特征），
			- （完备族的证明）
			  collapsed:: true
				- 完备族的基本证明方式为根据定义$E_{\theta}(T) = \int_{S_{X}}f_{T}(X)dx = 0$，寻找可能的函数T(X)，
				- 常见的（支集不依赖于参数）分布族一般都是完备族，
			- 无偏估计量W
			  collapsed:: true
				- R-B定理对无偏估计量没有严格要求，
				- 因此，应选取易于计算的无偏估计量，
				- 有时可基于样本X_{1}设置无偏估计量，
			- 条件期望的求解
			  collapsed:: true
				- 按照R-B定理和L-S定理，条件期望E(W | T) = h(T)为UMVUE，
				  collapsed:: true
					- 无偏估计量W一般与充分统计量T相关，因此其联合分布f(W, T)一般较难直接求解，
					- 如果可以根据T和W的关系，将条件概率转化为无条件概率，则可以简化运算，
				- 离散情况
				  collapsed:: true
					- 一般可拆分充分统计量T，转为无条件概率，
					- 即$P(W | T) = \dfrac{P(W, T)}{P(T)} = \dfrac{P(W = w, T = t)}{P(T = t)} = \dfrac{P(W = w, T' = t - w)}{P(T = t)} = \dfrac{P(W = w)P(T' = t - w)}{P(T = t)}$，
				- 连续情况
				  collapsed:: true
					- 一般充分统计量难以直接拆分，
					- 基本方法为按定义求解$E(W | T) = \int_{S_{W|T}}wf(W | T)dw = \int_{S_{W|T}}w\dfrac{f(W, T)}{f(T)}dw$，
					- 可以尝试利用Basu定理，将其转化为无条件概率，
					  collapsed:: true
						- 对于位置族，$P(W < w | T = t) = P(W - T < w - t | T = t) = P(W - T < w - t)$，
						- 对于尺度族，$P(W < w | T = t) = P(\dfrac{W}{T} < \dfrac{w}{t} | T = t) = P(\dfrac{W}{T} < \dfrac{w}{t})$，
			- 技巧
			  collapsed:: true
				- 充分统计量的设置
				  collapsed:: true
					- 理论上，充分统计量应包括“所有”在题目中出现的样本，
					- 例如，求$P(\sum \limits _{i= 1}^{n}X_{i} > X_{i + 1})$的UMVUE时，充分统计量应设为$\sum \limits _{i= 1}^{n + 1}X_{i}$，
				- 条件概率在不同情况下的取值不同，
					- 应区分不同情况（事件），逐个计算对应的概率，
					- 一般应以充分统计量的取值为分段标准，
			- 示例
			  collapsed:: true
				- 对于$X_{i} \sim b(1, p)$，求$P(\sum \limits _{i= 1}^{n}X_{i} > X_{n + 1})$的UMVUE，
				- 充分统计量
				  collapsed:: true
					- 设充分统计量$T = \sum \limits _{i= 1}^{n + 1}X_{i}$，
					- 由二项分布的可加性，可知$T \sim b(n + 1, p)$，
				- 无偏估计量
				  collapsed:: true
					- 设无偏估计量$W = \begin{cases}  1 & P(T=\sum \limits _{i= 1}^{n + 1}X_{i} > 2X_{n + 1}) \\ 0 & 其它 \end{cases}$，
					- 可知，$EW = 1 \cdot P(T > 2X_{n + 1}) + 0 = P(T > 2X_{n + 1})$，
				- 求解条件期望
					- 由R-B定理，可知基于充分统计量的无偏估计量为UMVUE，
					- 即$\varphi(T) = E(W | T)$为UMVUE，
					- 由条件期望的定义，$\varphi(T) = E(W | T) = 1 \cdot P(W | T) + 0 = P(W | T)$，
					- 由条件概率的定义，$P(W | T) = \dfrac{P(W, T)}{P(T)} = \dfrac{P(\sum \limits _{i= 1}^{n + 1}X_{i} > 2X_{n + 1}, \sum \limits _{i= 1}^{n + 1}X_{i} = t)}{P(\sum \limits _{i= 1}^{n + 1}X_{i} = t)}$
					  id:: 62ba5cef-5217-4bd0-902a-863f7d9ef8f3
					- 按照充分统计量T的值分段讨论，
					  collapsed:: true
						- T = 0时，一定有X_{n + 1} = 0；此时P(T > 2X_{n + 1}) = 0，即P(W | T) = 0，
						- T = 1或2时，
							- X_{n + 1} = 1时，仍有P(T > 2X_{n + 1}) = 0，即P(W | T) = 0，
							- X_{n + 1} = 0时，
								- $P(W | T) = \dfrac{P(\sum \limits _{i= 1}^{n + 1}X_{i} > 0, \sum \limits _{i= 1}^{n + 1}X_{i} = t)P(X_{n + 1} = 0)}{P(\sum \limits _{i= 1}^{n + 1}X_{i} = t)} = \dfrac{{n \choose t}{\theta}^{t}{(1 - \theta)}^{n - t}(1 - \theta)}{{n + 1 \choose t}{\theta}^{t}{(1 - \theta)}^{n + 1 - t}} = \dfrac{n \choose t}{n + 1 \choose t}$，
						- T ≥ 3时，
							- 无论X_{n + 1} = 1或0，P(T > 2X_{n + 1})都是必然事件，即P(T > 2X_{n + 1}) = 1，
							- 此时条件期望$P(W | T) = \dfrac{P(\sum \limits _{i= 1}^{n + 1}X_{i} > 2X_{n + 1}, \sum \limits _{i= 1}^{n + 1}X_{i} = t)}{P(\sum \limits _{i= 1}^{n + 1}X_{i} = t)} = \dfrac{P(\sum \limits _{i= 1}^{n + 1}X_{i} = t)}{P(\sum \limits _{i= 1}^{n + 1}X_{i} = t)} = 1$，
				- 综上所述，UMVUE为$\begin{cases}  0 & T(\sum \limits _{i= 1}^{n + 1}X_{i}) = 0 \\ \dfrac{n + 1 - T}{n + 1} & T(\sum \limits _{i= 1}^{n + 1}X_{i}) = 1,2 \\ 1 & T(\sum \limits _{i= 1}^{n + 1}X_{i}) \geq 3 \end{cases}$，
		- 微分法
		  collapsed:: true
			- 常用于分布的*支集*依赖于\theta，且密度函数f_{X}中的\theta，x可以分离时，
			- 设g(X)为h(\theta)的UMVUE，
			- 则按UMVUE的定义，应有$\int_{0}^{\theta}g(X)f_{X}(x;\theta)dx = h(\theta)$，
			- 分离密度函数中的\theta与x，写为$\int_{0}^{\theta}g(X)f_{1}(x)dx = h(\theta)f_{2}(\theta)$，
				- 由于左侧为对x积分，因此\theta的函数可以从积分号内提出，
			- 两侧对*参数θ*求导，可得$g(\theta)f_{1}(\theta) = h'(\theta)f'_{2}(\theta)$，
			- 因此，可知*函数g*的表达式应为$g(\theta) = \dfrac{h'(\theta)f'_{2}(\theta)}{f_{1}(\theta)}$，
			- 所以，UMVUE为$g(X) = \dfrac{h'(X)f'_{2}(X)}{f_{1}(X)}$，
-
-
-
- [[数理统计]]