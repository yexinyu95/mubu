- 大样本估计
  collapsed:: true
	- 当样本容量n \to \infty时，称统计推断的性质为大样本性质，
	- 当样本容量固定时，称统计推断的性质为小样本性质，
	- 两者的差距不在于具体的样本量的大小，而是推断的出发点，
- 随机变量序列
  collapsed:: true
	- 定义：一般为统计量$g_n = g(X_1, X_2, ...X_n)$，即不同的随机变量个数计算得到的统计量不同，
- 随机变量序列的收敛性
  collapsed:: true
	- [[概率的极限定理]]
	- （概率有界）
	  collapsed:: true
		- 对于随机变量序列{X_{N}}；若存在B > 0，N \in N+，对任意\epsilon > 0，
		- 在n ≥ N时，总有$P((|{X}_{n}| \leq B) \geq 1-  \varepsilon)$；则称X_{N}概率有界，
		- 定理
		  collapsed:: true
			- 若$X_{N} \stackrel{D} {\rightarrow} X$，则{X_{N}}一定概率有界，反之不成立，
			- 若{X_{N}}概率有界，$Y_{N} \stackrel{D} {\rightarrow} 0$，则$X_{N}Y_{N} \stackrel{P} {\rightarrow} 0$，
- 概率不等式
  collapsed:: true
	- [[概率计算]]
- 统计量的性质
	- 相合性
	  collapsed:: true
		- 定义
		  collapsed:: true
			- 设统计量X_{n}为参数\theta的估计量，
			- 若随机变量序列X_{n}收敛于参数\theta，则称X_{n}为\theta的一个相合估计，
			- 由于随机变量的收敛性的不同，统计量的相合性也可分为多种，
			- 一般考虑依概率收敛，即$X_{n} \stackrel{P} {\rightarrow} \theta$，
		- 判断
		  collapsed:: true
			- 依概率收敛的定义（极限运算）
			  collapsed:: true
				- 对于随机变量序列{X_{N}}，若$\lim\limits_{n \to \infty} P(|X_n - θ| \geq \varepsilon) = 0(\varepsilon > 0)$，则称$X \stackrel{P} {\rightarrow} \theta$，
				- 技巧
				  collapsed:: true
					- 另一种形式$\lim\limits_{n \to \infty} P(|X_n - θ| < \varepsilon) = \lim\limits_{n \to \infty} P(\theta - \varepsilon < X_n < \theta + \varepsilon) = 1$，一般较方便计算，
					- 拆绝对值符号时，应注意θ和X的支集；如对于均匀分布U(0, θ)总有X < θ，即$P(|X - θ| < \epsilon) = P(θ - X < \epsilon)$，
			- 依概率收敛的性质（代数运算）
			- 无偏估计定理
			  collapsed:: true
				- 定理：若X_{n}为参数\theta的无偏估计，则$\lim\limits_{n \to \infty}\operatorname{Var}X_{n}  \rightarrow 0$时，有$X \stackrel{P} {\rightarrow} \theta$，
				- 推导
				  collapsed:: true
					- 根据依概率收敛的定义和Chebyshev不等式，可知$\lim\limits_{n \to \infty} P(|X_n - θ| \geq \varepsilon) \leq \dfrac{E_{\theta}[{(X_{n} - \theta)}^{2}]}{\varepsilon^{2}}$，
					- 拆分分子的期望式$E_{\theta}[{(X_{n} - \theta)}^{2}] = \operatorname{Var}X_{n} + {[E(X_{n}) - \theta]}^{2}$，
					- 因此，X_{n}为无偏估计时，可得$\lim\limits_{n \to \infty} P(|X_n - θ| \geq \varepsilon) \leq \dfrac{\operatorname{Var}X_{n}}{\varepsilon^{2}}$，
	- （渐近）有效性
	  collapsed:: true
		- 极限方差与渐近方差
		  collapsed:: true
			- 定义
			  collapsed:: true
				- 对于统计量X_{n}和数列k_{n}，若$\lim\limits_{n \to \infty}k_{n}\operatorname{Var}X_n = {\sigma}_{1}^{2}$，则称${\sigma}_{1}^{2}$为极限方差，
				  collapsed:: true
					- 数列k_{n}为标准化系数，
					- 对于一般统计量（如样本均值$\operatorname{Var} \overline {X} = \dfrac{{\sigma}^{2}}{n}$），$n \to \infty$时有$\operatorname{Var}X_n \to 0$，不易于直接分析，
				- 对于统计量X_{n}和数列k_{n}，若$k_{n}(X_{n} - \theta) \stackrel{D} \rightarrow N(0, {\sigma}_{2}^{2})$，则称${\sigma}_{2}^{2}$为渐进方差，
				- 一般极限方差与渐近方差相等，即可以用极限方差近似渐近方差；但总体上看，${\sigma}_{2}^{2} \leq {\sigma}_{1}^{2}$，
		- 渐近相对效率ARE
		  collapsed:: true
			- 设X_{n}，Y_{n}为关于同一参数g(\theta)的两个估计量，称两者的渐近方差之比为渐近相对效率，
			- 即对于$\sqrt{n}(X_{n} - g(\theta)) \stackrel{D} \rightarrow N(0, {\sigma}_{x}^{2})$，$\sqrt{n}(Y_{n} - g(\theta)) \stackrel{D} \rightarrow N(0, {\sigma}_{y}^{2})$；有$\text{ARE} (X_{n}, Y_{n}) = \dfrac{{\sigma}_{y}^{2}}{{\sigma}_{x}^{2}}$，
		- （渐近）有效估计
		  collapsed:: true
			- 设g(X)为h(\theta)的无偏估计，
			- 若g(X)的（渐近）方差达到了C - R不等式的下界，即$\text{ARE} = \dfrac{[g'(\theta)]^{2} / nI(\theta)}{\text{Var}[g(X)]} = 1$，
			- 则称g(X)为一个（渐近）有效估计，
	- 大数定律
	  collapsed:: true
		- 切比雪夫大数定律
		  collapsed:: true
			- 若X_{i}为不相关随机变量，则$\lim\limits_{n \to \infty}P(|\dfrac{\sum {X}_{i}}{n} - \dfrac{\sum E{X}_{i}}{n}| < \varepsilon) = 1$，
		- 伯努利大数定律
		  collapsed:: true
			- 若$X_{n} \sim b(n, p)$，则$\lim\limits_{n \to \infty}P(|\dfrac{{X}_{n}}{n} - p| < \varepsilon) = 1$，
		- 辛钦大数定律
			- 若总体X有均值μ，Xi为独立同分布样本，则统计量$\overline X \stackrel{P} {\rightarrow} \mu$，
		- （应用）
		  collapsed:: true
			- 利用频率收敛于概率的性质，做多次实验来求得近似的概率值，
			- 利用区间足够小的直方图近似概率密度函数，
			- 蒙特卡洛积分
				- 希望求解积分$\int_{a}^{b} g(x)dx$，但g(X)的形式较复杂，
				- 可将积分写为$\int_{a}^{b} g(x)dx = (b - a)\int_{a}^{b} g(x) \frac{1}{b - a}dx$，
				- 将$\frac{1}{b - a}$看成$U(a, b)$的密度函数，X看成随机变量，
				- 上述积分可写为$\int_{a}^{b} g(x)dx = (b - a)E[g(X)]$，其中$X \sim U(a, b)$，
				- 因此，可设$Y = (b - a)g(X)$，则有$EY = (b - a)E[g(X)]$，
				- 由*大数定律*，可知$\overline {Y} \stackrel{P} {\rightarrow} EY$，
				- 因此，可生成X_{i}的随机数，并计算对应的Y_{i}，然后利用多个Y_{i}计算均值来估计积分，
- 分布的性质
	- 渐近正态性
	  collapsed:: true
		- 定义
		  collapsed:: true
			- 设统计量X_{n}为参数\theta的估计量，
			- 若存在两个数列a_{n}(\theta)，b_{n}(\theta)，使得随机变量序列$\dfrac{X_{n} - a_{n}(\theta)}{b_{n}(\theta)} \stackrel{D}{\rightarrow} N(0, 1)$，
			- 则称X_{n}为渐近正态的，
			- 一般形式为$\sqrt{n}{(X_{n} - \theta)} \stackrel{D}{\rightarrow} N(0, h(\theta))$，
		- 渐近有效性
		  collapsed:: true
			- $(X_{n} - \theta) \stackrel{D}{\rightarrow} N(0, \dfrac{1}{nI(\theta)})$，
			- 即渐近方差达到了C-R不等式下界，
		- mle的渐近正态性，
	- 渐近分布的求解
	  collapsed:: true
		- 依分布收敛的定义（极限运算）
		  collapsed:: true
			- 对于随机变量序列{X_{N}}和随机变量X，若对所有使F_{X}连续的点的集合，都有$\lim\limits_{n \to \infty} F_{X_{N}} = F_{X}$，则称$X_{N} \stackrel{D} {\rightarrow} X$，
			- 求解时需要根据cdf的表达式，计算对应极限，
			- 理论上，pdf的表达式$\lim\limits_{n \to \infty} f(X_n) = f(X)$不能说明依分布收敛，但有时也可应用，
			- 示例
			  collapsed:: true
				- 设$X \sim U(0, 1)$，$Y_{n}$为最大次序统计量，统计量$T = n(1 - Y_{n})$，
				- 可算得$F_{Y}(y) = y^{n}I_{\{0 < y <1\}}$，
				- 则$F_{T}(t) = P(T \leq t) = P(n(1 - Y_{n}) \leq t)$，
				- $= 1 - P(Y_{n} \leq (1 - \dfrac{t}{n})) = 1 - {(1 - \dfrac{t}{n})}^{n}$，
				- 由极限运算，可知$\lim\limits_{n \to \infty} F_{T}(t) = \lim\limits_{n \to \infty} 1 - {(1 - \dfrac{t}{n})}^{n} = 1 - {e}^{-t}$，
				- 因此，$T \stackrel{D} {\rightarrow} 1 - {e}^{-t} = \text{Exp}(1)$，
		- 中心极限定理（Levy）
		  collapsed:: true
			- 若总体X有均值μ、方差σ2；Xi为独立同分布样本，则$\overline X \stackrel{D} {\rightarrow} N(\mu, \dfrac{\sigma^2} {n})$，或$\Sigma X_i \stackrel{D} {\rightarrow} N(n\mu, n\sigma^2)$，
			- 一般写为$\sqrt[] n(\overline X - \mu) \stackrel{D} {\rightarrow} N(0, \sigma^2)$，可以保证n→∞时方差不为0，
		- 矩母函数方法
		  collapsed:: true
			- 设随机变量序列{X_{n}}的矩母函数为M_{Xn}，随机变量X的矩母函数为M_{X}，
			- 若$\lim\limits_{n \to \infty}M_{X_{n}}(t) = M_{X}(t)$，则$X_{N} \stackrel{D} {\rightarrow} X$，
			- 特别的，若$M_{X_{n}}(t)$可以写为（或Taylor展开为）${(1 + \frac{b(t)}{n} + \frac{\phi(n)}{n})}^{c(t)n}$，
			- 则$\lim\limits_{n \to \infty}\phi(n) = 0$时，有$\lim\limits_{n \to \infty}M_{X_{n}}(t) = e^{b(t)c(t)}$，
			- 理论上需要连续性定理作为保证，因为矩母函数列的弱收敛函数*不一定*是矩母函数，
	- 随机变量的函数的收敛
		- Slutsky定理
		  collapsed:: true
			- 定理
			  collapsed:: true
				- 若$X_{N} \stackrel{D} {\rightarrow} X$；$A_{N} \stackrel{P} {\rightarrow} a$，$B_{N} \stackrel{P} {\rightarrow} b$，
				  id:: 62b52899-ee14-449e-b8c1-6dce4f6fe42c
				- 则$A_{N} + B_{N}X_{N} \stackrel{D} {\rightarrow} a + bX$，
				- $A_{N} \stackrel{P} {\rightarrow} 0$，$B_{N} = 1$时，$A_{N} + X_{N} \stackrel{D} {\rightarrow} X$，
				- $A_{N} = 0$，$B_{N} \stackrel{P} {\rightarrow} 1$时，$B_{N}X_{N} \stackrel{D} {\rightarrow} X$，
			- 示例
			  collapsed:: true
				- 例如t统计量$t_{N} = \dfrac{{\overline{X}}}{S/\sqrt{n}} = \dfrac{\sqrt{n}\overline{X}}{\sigma} \cdot \dfrac{\sigma}{S}$，
				- 其中，$\dfrac{\sqrt{n}\overline{X}}{\sigma} \stackrel{D} {\rightarrow} Z_{N}$，$\dfrac{\sigma}{S} \stackrel{P} {\rightarrow} 1$，
				- 因此，由Slutsky定理，可知$t_{N} \stackrel{D} {\rightarrow} N(0, 1)$，
		- 推广：Δ方法
			- 一阶
				- 若$\sqrt{n}(X_{n} - \theta) \stackrel{D} \rightarrow N(0, {\sigma}^{2})$，则$\sqrt{n}[g(X_{n}) - g(\theta)] \stackrel{D} \rightarrow N(0, {\sigma}^{2}{[g'(\theta)]}^{2})$，
				- 证明（Taylor多项式）
				  collapsed:: true
					- 设X为随机变量，其期望EX = \mu，方差Var X = \sigma^{2}；且$X_{N} \stackrel{D} {\rightarrow} N(\mu, \dfrac{{\sigma}^{2}}{n})$，
					- 由一阶Taylor多项式：g(X) \approx g(\mu) + g'(\mu)(X - \mu) + o(X - \mu) = [g(\mu) - g'(\mu)\mu] + g'(\mu)X，
					- 此处g(\mu) - g'(\mu)\mu，g'(\mu)都是常数，
					- 所以由Slutsky定理和正态分布的性质，可知g(X)的近似分布为$N(g(\mu), \dfrac{{\sigma}^{2}{[g'(\mu)]}^{2}}{n}))$，
			- 二阶
			  collapsed:: true
				- 若g'(\theta) = 0，则可使用二阶Δ方法，
				- 若$\sqrt{n}(X_{n} - \theta) \stackrel{D} \rightarrow N(0, {\sigma}^{2})$，则$\sqrt{n}[g(X_{n}) - g(\theta)] \stackrel{D} \rightarrow {\sigma}^{2}\dfrac{[g''(\theta)]}{2}{\chi}^{2}(1)$，或$\Gamma(\dfrac{1}{2}，\dfrac{1}{{\sigma}^{2}g''(\theta)})$，
			- 多元
			  collapsed:: true
				- 若$E\vec{X} = \vec{\theta}$，则$Eg(\vec{X}) \approx g(\vec{\theta})$，
				- $\operatorname{Var}[g(\vec{\theta})] \approx {(\dfrac{\partial g(\vec{\theta})}{\partial {\theta}_{1}})}^{2}\operatorname{Var}{X}_{1} + {(\dfrac{\partial g(\vec{\theta})}{\partial {\theta}_{2}})}^{2}\operatorname{Var}{X}_{2} + ... + 2{(\dfrac{\partial g(\vec{\theta})}{\partial {\theta}_{1}})}{(\dfrac{\partial g(\vec{\theta})}{\partial {\theta}_{2}})}\operatorname{Cov}(X_1, X_2)+...$，
			- 应用：期望与方差的近似
			  collapsed:: true
				- 若EX = \mu，Var X = \sigma^{2}，则E[g(X)] \approx g(\mu)，Var [g(X)] \approx [g'(\mu)]^{2}\sigma^{2}，
				  collapsed:: true
					- 例如，$E(\dfrac{1}{X}) \approx \dfrac{1}{\mu}，\text{Var}(\dfrac{1}{X}) \approx [-\dfrac{1}{{\mu}^{2}}]^{2}\sigma^{2} = \dfrac{\sigma^{2}}{{\mu}^{4}}$，
				- 若$EX = \mu_{1}，\text{Var}X = \sigma_{1}^{2}，EY = \mu_{2}，\text{Var}Y = \sigma_{2}^{2}，\text{Cov}(X, Y) = \rho\sigma_{1}\sigma_{2}$，
				- 则$E[g(X, Y)] \approx g(\mu_{1}, \mu_{2})$，$\text{Var} [g(X, Y)] \approx {(\dfrac{\partial g(\mu_{1}, \mu_{2})}{\partial {\mu}_{1}})}^{2}\sigma_{1}^{2} + {(\dfrac{\partial g(\mu_{1}, \mu_{2})}{\partial {\mu}_{2}})}^{2}\sigma_{2}^{2} + 2{(\dfrac{\partial g(\mu_{1}, \mu_{2})}{\partial {\mu}_{1}})}{(\dfrac{\partial g(\mu_{1}, \mu_{2})}{\partial {\mu}_{2}})}\rho\sigma_{1}\sigma_{2}$，
				  collapsed:: true
					- 例如，$E(\dfrac{X}{Y}) \approx \dfrac{\mu_{1}}{\mu_{2}}，\text{Var}(\dfrac{X}{Y}) \approx (\dfrac{1}{{\mu}_{2}})^{2}\sigma_{1}^{2} + (-\dfrac{\mu_{1}}{{\mu}_{2}^{2}})^{2}\sigma_{2}^{2} + 2(\dfrac{1}{{\mu}_{2}})(-\dfrac{\mu_{1}}{{\mu}_{2}^{2}})\rho\sigma_{1}\sigma_{2}$，
		- 注释
		  collapsed:: true
			- 具体使用时，应关注主要随机变量的依分布收敛性（极限分布函数），其它随机变量只需要关注其依概率收敛性（相合估计）即可，
			- 一般方法为先求出参数的函数的mle、UMVUE，再求解估计量的期望与方差；再综合中心极限定理和Slutsky定理求解极限分布，
			- 使用Δ方法求近似分布时，应使参数的形式尽量简单，
		- （方差不依赖于参数的统计量的构造）
		  collapsed:: true
			- 设统计量$Y \sim b(n, p)$，
			- 统计量的渐近分布
			  collapsed:: true
				- $\frac{Y}{n} \stackrel{D}{\rightarrow}  N(p, \dfrac{p(1 - p)}{n})$，
			- 统计量的函数的渐近分布
			  collapsed:: true
				- 设统计量T = T(Y/n)，
				- 由Δ方法，可知$T(\frac{Y}{n})  \stackrel{D}{\rightarrow}  N(T(p)，{[T'(p)]}^{2}\dfrac{p(1 - p)}{n})$，
			- 构造（微分）方程
			  collapsed:: true
				- 设${[T'(p)]}^{2}{p(1 - p)} = c$(常数)，
				  collapsed:: true
					- 此处的方差不包括参数n，
				- 可得微分方程$T'(p) = \sqrt{c}\dfrac{1}{\sqrt{p(1 - p)}}$，
				- 解得$T(p) = \sqrt{c} \cdot 2\arcsin(\sqrt{p})$，
				- 设$c = \frac{1}{4}$，则$T(p) = \arcsin(\sqrt{p})$，${[T'(p)]}^{2}{p(1 - p)} = \frac{1}{4}$
				- 带回原式，可得$\arcsin(\sqrt{\frac{Y}{n}})  \stackrel{D}{\rightarrow}  N(\arcsin(\sqrt{p}), \dfrac{1}{4n})$，
	- 其它
	  collapsed:: true
		- （生成随机样本：直接法、间接法、舍选法）
		- （MCMC方法）
		- （自助法Bootstrap）
- 渐近分布的应用
  collapsed:: true
	- 次序统计量的极限分布
	  collapsed:: true
		- 设随机变量X的 pdf 为f_{X}(x)，其p分位数为\xi_{p}，
		- 样本量为n，常数m = np，
		- 则样本的次序统计量X_{(m)}可作为p分位数为\xi_{p}的一个点估计，
		- 且有渐近分布：$f(\xi_{p})\dfrac{\sqrt{n}(X_{(m)} - \xi_{p})}{\sqrt{p(1- p)}} \stackrel{D} {\rightarrow} N(0, 1)$，
		- （@证明）
		  collapsed:: true
			- 由中心极限定理，设$a_{n}(X_{(m)} - \xi_{p}) \stackrel{D} {\rightarrow} N(0, 1)$，
	- 大样本假设检验
	  collapsed:: true
		- 似然比的渐近分布
		  collapsed:: true
			- 检验统计量：$\Lambda = \dfrac{L(H_{0})}{L(H_{1})} = \Lambda(\vec{X}; \vec{\theta}_{H_{0}})$，
			- 检验水平
				- 似然比的渐进分布：$-2\ln \Lambda \stackrel{D}{\rightarrow} {\chi}^{2}(n)$，
				- n = \Omega时可自由变动的参数 - H_{0}时可自由变动的参数，
		- Wald检验
		  collapsed:: true
			- 检验统计量：$W_{n} = \hat{\theta}$，一般使用参数的mle估计，
			- 检验水平
			  collapsed:: true
				- W_{n}的渐进分布：$W_{n} \stackrel{D}{\rightarrow} N(\theta_{H_{0}}, \dfrac{1}{nI(\hat{\theta})})$，
					- 可转化为标准正态统计量${\sqrt{nI(\hat{\theta})}}{(W_{n} - \theta_{H_{0}})} \stackrel{D}{\rightarrow} N(0, 1)$，
					- （也可进一步转化为卡方统计量）,
					- 此处的信息量$I(\hat{\theta}) = I({\theta})|_{{\theta} = \hat{\theta}}$，即使用估计量（样本）来计算信息量，
		- 得分检验
		  collapsed:: true
			- 检验统计量：$S = \dfrac{\partial \ln L}{\partial \theta}|_{\theta = \theta_{H_{0}}}$，
			- 检验水平
			  collapsed:: true
				- 由得分统计量的性质，可知$S(\theta_{H_{0}}) \stackrel{D}{\rightarrow} N(0，nI(\vec{\theta}_{H_{0}}))$，
				- 可转化为标准正态统计量$\dfrac{1}{\sqrt{nI(\theta_{H_{0}})}}(S(\theta_{H_{0}}) - 0) \stackrel{D}{\rightarrow} N(0, 1)$，
				- 此处的信息量$I({\theta})$为H_{0}成立时的样本信息量，一般为常数，
		- 示例
		  collapsed:: true
			- 设X \sim b(1, p)，X_{i}为样本，样本数为n，
			- 得分函数S(p) = $\frac{X}{p} - \frac{1-X}{1-p}$，
			- X的信息量I(p) = $\frac{1}{p(1 - p)}$，由于X_{i}独立同分布，所以联合分布的信息量为$\frac{n}{p(1 - p)}$，
			- 充分统计量为\Sigma X_{i}，mle为$\hat{p} = \frac{\Sigma X_{i}}{n}$，
			- Wald统计量：${\sqrt{I(\hat{\theta})}}{(W_{n} - \theta_{H_{0}})} = \sqrt \frac{n}{\hat{p}(1 - \hat{p})}(\hat{p} - p_{0})$，
			- 联合分布的得分函数S(p) = $\frac{\Sigma X_{i}}{p} - \frac{n-\Sigma X_{i}}{1-p} = \frac{n}{p(1 - p)}(\hat{p} - p)$，
			- 得分统计量：$\dfrac{1}{\sqrt{I(\theta_{H_{0}})}}S(\theta_{H_{0}}) = \sqrt \frac{n}{p_{0}(1 - p_{0})}(\hat{p} - p_{0})$，
	- 大样本区间估计
	  collapsed:: true
		- 大样本枢轴量
		  collapsed:: true
			- 引理：若统计量W，V在$n \to \infty$时，有$\dfrac{W - \theta}{V} \stackrel{D}{\rightarrow} N(0, 1)$，则可基于统计量W，V构造置信区间，
			- mle的渐近有效性
			  collapsed:: true
				- $\sqrt{n}[\hat{\theta}(\vec{X}) - \theta] \stackrel{D}{\rightarrow} N(0, \dfrac{1}{I(\theta)})$，
					- 此处的Fisher信息量 I(\theta)由总体的pdf f_{X}(x ; \theta)算出，
				- 因此可构造近似区间$\sqrt{nI(\hat{\theta})}{(\hat{\theta}(\vec{X}) - \theta)} \stackrel{D}{\rightarrow} N(0, 1)$，
				- 即$P(-z_{\frac{\alpha}{2}} \leq \sqrt{nI(\hat{\theta})}{(\hat{\theta}(\vec{X}) - \theta)} \leq z_{\frac{\alpha}{2}}) = 1 - \alpha$，
		- 使用规则
			- 为了减小误差，应在近似统计量中多用参数，少用统计量；
			- 然而，参数的区间求解会变得复杂，
			- 示例
			  collapsed:: true
				- 对于泊松分布P(\lambda)，理论上枢轴量$T_{1} = \dfrac{\overline{X} - \lambda}{\sqrt{\lambda} / \sqrt{n}}$要优于$T_{2} = \dfrac{\overline{X} - \lambda}{S / \sqrt{n}}$，
				- 然而，求解区间$P(-u_{\frac{\alpha}{2}} < T < u_{\frac{\alpha}{2}}) = 1 - \alpha$时，枢轴量T_{1}的计算量较大，可能需要求解二次方程；而枢轴量T_{2}则只需基本的恒等变形即可，
		- LRT统计量
		- Wald统计量
		- 得分统计量
		- 若ARE(T_{1}, T_{2}) = k，则为了得到等长置信区间，使用T_{2}做枢轴量时的样本数量n应为T_{1}的k倍，
- 稳健估计
  collapsed:: true
	- 稳健性
	  collapsed:: true
		- 在保证估计效率的条件下，使小偏差和较大偏差产生的损失都可控，
	- 崩溃值
	  collapsed:: true
		- 定义
		  collapsed:: true
			- 设X为总体，$X_{1}, X_{2},..., X_{n}$为样本，T_{n}为统计量；$Y_{1}, Y_{2},..., Y_{n}$为次序统计量，
			- 设常数b \in [0, 1]，若$Y_{[(1 - b)n]} \to \infty$时，T_{n}仍为常数；但$Y_{[(1 - b)n] - 1} \to \infty$时，有T_{n} \to \infty，
				- （从最大次序统计量逐个往前算），
			- 则称b为统计量T_{n}的崩溃值，
		- 示例
		  collapsed:: true
			- 样本均值的崩溃值$b_{\overline {X}} = 0$，即$Y_{n} \to \infty$时，就有$\overline {X} \to \infty$，
			- 样本中位数的崩溃值$b_{m} = \frac{1}{2}$，即$Y_{n} \to \infty$时，中位数m保持不变；直到$Y_{[\frac{1}{2}n] - 1} \to \infty$时，才有$m \to \infty$，
	- 中位数的极限分布
	- M-估计量
-
- [[概率的极限定理]]
- [[数理统计]]