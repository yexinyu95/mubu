- 估计量的定义
	- 任意一个统计量就是一个估计量，即估计量不能含有（未知）参数，
- 点估计量的求解
	- 矩估计
		- 求解
		  collapsed:: true
			- 方法为令k阶样本矩 = k阶总体矩，
			  collapsed:: true
				- 此处的矩可以为中心矩或原点矩，
				- $E[X^{k}] = \dfrac{1}{n}\sum  \limits _{i = 1}^{n}X_{i}^{k}$，
				- $E[X-EX]^{k} = \dfrac{1}{n}\sum  \limits _{i = 1}^{n}(X_{i} - \bar{X})^{k}$，
			- 技巧
			  collapsed:: true
				- 一般k个参数需要联立k个方程，
				- 有时一阶矩可能难以求解，此时应使用高阶矩来辅助计算，
				- 理论上，求解矩估计无需准确的总体分布，
				- 对于限制范围的\theta，矩估计的求解方法不变，
			- 矩估计的理论基础为大数定律，
			- 参数的函数（不变性）
			  collapsed:: true
				- 若函数g(x)为连续函数，统计量T为参数\theta的矩估计，则g(T)为g(\theta)的矩估计，
				- 由矩估计的无偏性，可知一般只在g(\theta)为样本原点矩的线性组合时，其矩估计g(T)才是无偏估计，
		- 性质
		  collapsed:: true
			- 不唯一性
			  collapsed:: true
				- 矩估计不唯一，有时参数可能对应多个样本矩的值，如泊松分布的均值和方差，
				- 若存在多个矩估计，一般先考察矩估计量的无偏性，方差等性质，
			- 无偏性
			  collapsed:: true
				- k阶样本原点矩为k阶总体原点矩的无偏估计，
				- k \ge 2时，k阶样本中心矩不是k阶总体中心矩的无偏估计，
			- 渐近无偏性
			- 相合性
			  collapsed:: true
				- 矩估计（原点矩和中心矩）一般具有强相合性，
				- 若g(\theta)为连续函数，则g(T)为g(\theta)的强相合估计，
			- （渐近正态性）
		- （矩匹配）
		  collapsed:: true
			- 假设Y = g(X)，X的分布和函数g(X)已知，但Y的准确分布难以求得，
			- 可以通过X的分布估计Y的近似分布，并求解对应的总体矩EY；再通过E[g(X)]求解Y的样本矩，
			- 最后分析样本矩与总体矩，得出Y的参数的一个估计，
		- Satterthwaite近似（卡方分布）
		  collapsed:: true
			- 总体
			  collapsed:: true
				- $X_{1}, X_{2},..., X_{n}$为独立的卡方随机变量，其自由度分别为r_{i}，
				- 设$Y = \sum\limits_{i =1}^{n} a_i{X}_{i}$，其中a_{i}为已知常数，
				  id:: 62b1405b-fea5-4c00-9122-7aaed720f97d
				- 则Y也为随机变量，但Y的准确分布较难求得，
			- 估计方法
			  collapsed:: true
				- 设Y的近似分布为$\dfrac{{\chi}^{2}_{v}}{v}$，
				- $EY = E(\sum\limits_{i =1}^{n} a_i{X}_{i}) = \sum\limits_{i =1}^{n} {a}_{i}E({X}_{i}) = \sum\limits_{i =1}^{n} {a}_{i}{r}_{i}$，
				- $E(\dfrac{{\chi}^{2}_{v}}{v}) = 1$，
				- 由矩匹配方法，可设$\sum\limits_{i =1}^{n} {a}_{i}{r}_{i} = 1$，
				- （利用二阶矩匹配）
			- 估计分布
			  collapsed:: true
				- $Y \sim \dfrac{{\chi}^{2}_{v}}{v}$，
				- 设*X_{i}*为总体，则参数v的估计值为$\dfrac{{(\sum{a}_{i}{X}_{i})}^{2}}{\sum\dfrac{{a}_{i}^{2}}{{r}_{i}}{X}_{i}^{2}}$，
	- 极大似然估计
		- 似然函数
			- 定义
			  collapsed:: true
				- 设样本的*联合分布*$f_{\vec{X}}(x_{1}, x_{2},..., x_{n}; {\theta}_{1}, {\theta}_{2},..., {\theta}_{m})$，
				- 对确定的样本值$\vec{X} = \vec{x}$，称*关于参数θ*的函数$L_{\vec{\theta}}({\theta}_{1}, {\theta}_{2},..., {\theta}_{m}; x_{1}, x_{2},..., x_{n})$为似然函数，
				- 一般似然函数的对数形式易于处理，记为$\ln L = l(\theta, x)$
			- 求解
			  collapsed:: true
				- 似然样本的定义为样本的*联合分布*，应注意具体问题具体分析，
				- n个独立同分布样本（一般情况）
				  collapsed:: true
					- 由独立同分布随机变量的性质，可知，
					- 样本联合分布$f_{\vec{X}}(x_{1}, x_{2},..., x_{n}; {\theta}_{1}, {\theta}_{2},..., {\theta}_{m}) = \prod \limits _{i = 1}^{n} f_{X_{i}}(x_{i}; {\theta}_{1}, {\theta}_{2},..., {\theta}_{m})$，
				- 样本之间不独立
				  collapsed:: true
					- 应根据其他信息，求解联合分布$f_{\vec{X}}(x_{1}, x_{2},..., x_{n}; {\theta}_{1}, {\theta}_{2},..., {\theta}_{m})$，
				- 样本来自不同分布的总体
				  collapsed:: true
					- 应根据总体的不同情况，分别写出对应的样本联合分布，
					- 例如，若总体$X \sim \begin{cases}  f_{X}(x) & case1 \\ g_{X}(x) & case2 \end{cases}$，样本为独立同分布，
					- 则样本联合分布需要对应写为$\vec{X} \sim \begin{cases}  f_{\vec{X}}(\vec{x}) = \prod f_{X}(x) & case1 \\ g_{\vec{X}}(\vec{x}) = \prod g_{X}(x) & case2 \end{cases}$，
					- 然后，依据样本的取值可能，对似然函数分段讨论，
				- 只有几个样本
				  collapsed:: true
					- 应寻找剩余样本的信息，并以概率的形式写入似然函数，
					- 例如，若观测到$X_{1}, X_{2},..., X_{m}$和部分剩余样本信息$X_{m + i} \geq t$，
					- 则似然函数应写为$f_{\vec{X}}(\vec{x}) = \prod \limits _{i = 1}^{m}f_{X_{i}}(x) \cdot \prod \limits _{j = m + 1}^{n}[P(X_{j} \geq t)] = {[f_{X}(x)]}^{m} \cdot {[1 - F_{X}{(t)}]}^{n - m}$，
			- 定理：在正则条件下，似然函数在参数的真值处渐近取得最大值，
		- 定义
		  collapsed:: true
			- 使L(θ)最大化的θ的取值为mle，
		- 求解
			- 微分法
			  collapsed:: true
				- 根据微积分理论，函数在驻点处取得极大值，
				- 即可以建立偏导数方程组$\dfrac{\partial L}{\partial \theta} = 0$，求解似然函数的驻点，
				- 解得的统计量为极大似然估计的可能取值，即一般需要验证驻点是否为极值点，
			- 分析似然函数性质
			  collapsed:: true
				- 部分情况下似然函数不能利用微积分方法分析，
				- 此时可以根据函数的单调性等性质，分析似然函数的可能的极值点，
				- 部分情况下，mle可能不唯一；如均匀分布U(\theta, \theta + 1)的似然函数恒为1，所以满足支集条件的所有样本都可以为mle，
			- 离散分布的极值
			  collapsed:: true
				- 部分离散情况的似然函数（如二项分布的参数n），可能难以通过微积分方法求解，
				- 由于参数的值域限制为整数，所以一种方式为直接根据似然比，求解使$\dfrac{L(\theta ; x)}{L(\theta - 1 ; x)} \ge 1$和$\dfrac{L(\theta + 1 ; x)}{L(\theta ; x)} < 1$的参数的值，
				- 一般仍需要使用数值方法，
			- 参数的函数（不变性）
			  collapsed:: true
				- 若函数g(x)为连续函数，统计量T为参数\theta的mle，则g(T)为g(\theta)的mle，
			- 技巧
			  collapsed:: true
				- 由于pdf总为正值，所以一般使用对数似然函数求解，可以简化计算，
				- 对于约束值域的mle，应综合似然函数，分析似然函数在限制区域上的性质，
				- 画图辅助分析
				- 特定参数的mle的求解可能不会用到所有样本，
				- 似然函数可能不需要每个样本的准确分布，而是只需要（充分）统计量的分布，
			- （离散情况）
			  collapsed:: true
				- 离散分布下，极值的等价条件为$\dfrac{L(\theta|x)}{L(\theta - 1)|x} \geq 1$且$\dfrac{L(\theta|x)}{L(\theta + 1)|x} > 1$，
		- 极值的验证
		  collapsed:: true
			- 微积分方法（逐次极大化）
			- 定理：若样本分布为指数族，则似然方程解为自然参数空间的内点时，该解就是mle，
		- mle的性质
		  collapsed:: true
			- 不唯一性
				- 由于似然函数的性质不同，mle可能不唯一，
			- 相合性与渐近正态性
			  collapsed:: true
				- mle一般不具有无偏性，
				- mle的大样本性质较为复杂，
				- 对于一些常见的分布，mle具有相合性与渐近正态性，
			- 充分性
			  collapsed:: true
				- 若mle（唯一）存在，则mle一定为参数的充分统计量的函数，
		- （似然原理）
		  collapsed:: true
			- 若对两个不同的样本点$\vec{X} = \vec{x_1}$和$\vec{X} = \vec{x_2}$，似然比$\dfrac{L(\theta|\vec{x_1})}{L(\theta|\vec{x_2})}$为不依赖于参数\theta的某数值$C(\vec{x_1}, \vec{x_2})$，
			- 则由$\vec{x_1}, \vec{x_2}$所做的关于参数\theta的推断应该相同，
		- （EM算法）
		- （刀切法）
- 估计量的评价
	- 估计量的性质
	  collapsed:: true
		- 无偏性
		- 渐近无偏性（大样本）
		- 相合性（大样本）
		  collapsed:: true
			- [[渐近估计与极限分布]]
	- 分布的信息
	  collapsed:: true
		- 得分函数 S(\theta)
		  collapsed:: true
			- 设X \sim f_{X}(x ; \theta)，称关于参数θ的函数$S(\theta ; x) = \dfrac{\partial \ln f_{X}} {\partial \theta}$为得分函数，
			  collapsed:: true
				- 应注意得分函数需要先取对数，
			- 性质
			  collapsed:: true
				- 一般得分函数中既有参数也有随机变量，所以得分函数也是*随机变量*，
				- 因此，得分函数具有数字特征：ES = 0，
				  collapsed:: true
					- 由pdf的正则性等式，$\int f_{X}(x ; \theta)dx = 1$，两侧对参数\theta求（偏）导，
					- 再根据对数函数的求导法则$\dfrac{\partial \ln f(x ; \theta)} {\partial \theta} = \dfrac{1}{f(x ; \theta)}\dfrac{\partial f(x ; \theta)} {\partial \theta}$可算得，
			- 多参数的情况
			  collapsed:: true
				- 多个参数时为向量$(\dfrac{\partial \ln f} {\partial \theta_1}, \dfrac{\partial \ln f} {\partial \theta_2}, \dfrac{\partial \ln f} {\partial \theta_3}...)$，
				- 其维度与*参数θ的个数*有关，而与*随机变量个数*无关，
		- Fisher 信息量 I(\theta)
		  collapsed:: true
			- 设X \sim f_{X}(x ; \theta)，称关于参数θ的函数$I(\theta) = E_{X}[S(\theta ; x)^2]$为Fisher 信息量，
			  collapsed:: true
				- 应注意Fisher 信息量需要先取对数，
				- I(\theta) 一般不是随机变量，
			- 计算
			  collapsed:: true
				- $I(\theta) = -E(\dfrac{\partial ^2 \ln f} {\partial \theta^2}) = E[(\dfrac{\dfrac{\partial f(x ; \theta)} {\partial \theta}}{f(x ; \theta)})^{2}]$，
				  collapsed:: true
					- 得分函数的期望ES = 0，即$\int \dfrac{\partial \ln f_{X}} {\partial \theta} f_{X}(x)dx = 0$，
					- 两端对参数θ求（偏）导，即可得到上述等式，
				- 一般求高阶偏导更容易计算，
				- 求Fisher 信息量的过程为求解期望，因此需要分析随机变量的具体形式，
			- 计算技巧
			  collapsed:: true
				- 若每个样本的分布为 f ，信息量为 I(θ)，则由n个独立同分布样本组成的联合分布L的信息量为nI(θ)，
				- 样本独立但不同分布时，也有$I_L(\theta) = \sum\limits_ {i =1} ^n I_{X_i}(\theta)$ ，
				- θ的充分统计量的pdf f_{T}(t)算出的信息量I_{T}，与样本联合分布L的信息量I_{L}相同，
				  collapsed:: true
					- 但算得的信息量不一定能达到C - R下界，
				- θ的辅助统计量的pdf的信息量为0，
				- 对于位置族分布X = \theta + t（如N(\mu，0)）；X的pdf关于θ的信息量为θ的常函数，t的pdf关于θ的信息量为0，
		- Fisher 信息矩阵
		  collapsed:: true
			- 由分布函数定义的n阶矩阵，其阶数为*参数*的个数，与随机变量维度无关，
			- 其中的第i行，第j个元素的信息量为$I_{ij} = -E(\dfrac{\partial ^2 \ln f} {\partial \theta _i \partial \theta _j}) = E(\dfrac{\partial \ln f} {\partial \theta _i}\dfrac{\partial \ln f} {\partial \theta _j})$，
	- Cramer - Rao不等式
	  collapsed:: true
		- （C-R正则分布族）
		  collapsed:: true
			- ![image.png](../assets/image_1668588899847_0.png){:height 211, :width 417}，
		- 定义
		  collapsed:: true
			- 设X_{i}为样本，W(X_{i})为基于X_{i}的统计量，
			- 则W的方差$\text{Var}(W) ≥\dfrac{[(E_\theta W)_\theta']^2} {I(\theta)}$；
			- I(θ)为样本的联合分布L的信息量，
		- 技巧
		  collapsed:: true
			- 若W为参数θ的无偏估计，则$EW = θ，(EW)' = 1$；此时C-R下界为$\dfrac{1}{I(θ)}$，
			- 若W为参数的函数g(θ)的无偏估计，则$EW = g(θ)，(EW)' = g'(θ)$；此时C-R下界为$\dfrac{[g'(θ)]^2}{I(θ)}$，
			- 若n个样本为独立同分布，则联合分布L的信息量为总体的n倍，即C-R下界为$\dfrac{1}{nI(θ)}$，
		- 有效性
		  collapsed:: true
			- 若无偏估计量W的方差达到了C-R不等式的下界，则称W为一个有效估计量，
			- 对于多个无偏估计量W_{1}，W_{2}；若VarW_{1} \le VarW_{2}，则称W_{1}比W_{2}有效，
		- （达到下界的条件）
		  collapsed:: true
			- 设g(\theta)为参数的函数，W(X)为其无偏估计，S(\theta)为得分函数，
			- 若存在某个函数a(\theta)，使得a(\theta)[W(X) - g(\theta)] = S(\theta)，
			- 则W的方差可以达到C-R下界，
			- 示例
			  collapsed:: true
				- 对于指数分布$f_{X}(x) = \lambda e^{-\lambda x}$，
				- 得分函数$S(\theta) = \dfrac{1}{\lambda} - X$，
				- 因此可知$(-1)(X - \dfrac{1}{\lambda}) = S(\theta)$，
				- 即只有$g(\lambda) = \dfrac{1}{\lambda}$有达到下界的无偏估计，
				- （若将分布写为$\frac{1}{\lambda} e^{-\frac{x}{\lambda}}$，则等式变为$( \dfrac{1}{\lambda^{2}})(X - {\lambda}) = S(\theta)$，此时参数\lambda有达到下界的无偏估计），
		- （多参数情况）
	- [[统计决策理论]]
- 无偏估计的求解
	- 最佳无偏估计量（UMVUE）
		- 引入
		  collapsed:: true
			- 由于对估计量的要求较为宽泛，所以在所有估计量的集合中求解“最佳”的估计量较为困难，即难以找到合适的标准，
			- 因此，一种标准为，将估计量限制在无偏的范围内，再利用损失函数来分析这些无偏估计量的最优性，
		- 定义
		  collapsed:: true
			- 若估计量W为无偏估计，即EW = \theta，
			- 且对于所有其它的无偏估计量W'，总有VarW ≤ VarW'；则称W为参数\theta的最小方差无偏估计量（MVUE），
			- 将上述定义中的参数\theta换为参数的函数g(\theta)，此时的W称为一致(uniformly)最小方差无偏估计量，
		- 可估性
		  collapsed:: true
			- 对于部分参数和其函数g(\theta)，可以反证其UMVUE不存在，
			- 称无偏估计存在的参数为可估参数，使参数的函数的无偏估计存在的函数为可估函数，
	- 定理
		- 0的无偏估计
		  collapsed:: true
			- 定理：设估计量W(X)为参数g(\theta)的无偏估计量，则W为最佳无偏估计量$\leftrightarrow \text{Cov}_{\theta}(W, U) = E_{\theta}(W\cdot U) = 0$；其中U(X)为0的无偏估计，即$E_{\theta}[U(X)] = 0$，
			- 求解
			  collapsed:: true
				- 一般方法为利用定义$E_{\theta}(U) = \int_{S_{X}}U(x)f_{X}(x)dx = 0$寻找可能的函数U(X)，再求解期望E(U, W)，
				- 也可以根据U(X)的性质$\int_{S_{X}}U(x)f_{X}(x)dx = 0$，尝试将其“转换”为$E_{\theta}(W\cdot U) = \int_{S_{X}}W(x)U(x)f_{X}(x)dx = 0$，
				- 一般需要通过对参数求导等方式分析，
			- 应用
			  collapsed:: true
				- 定理没有给出求解无偏估计W(X)的具体途径，
				- 此外，寻找所有0的无偏估计并不容易；
				- 因此该定理主要用于反证给定的统计量W(X)不是最佳无偏估计，
		- Rao-Blackwell
		  collapsed:: true
			- 基于充分统计量的无偏估计的方差（一致）更小，
			- 即设W为g(\theta)的无偏估计量，T为参数\theta的充分统计量，
			- 则由条件期望E(W | T)算得的统计量h(T)为一个比W更优（方差较小）的无偏估计量，
		- Lehmann-Scheffe
		  collapsed:: true
			- 若参数g(\theta)存在无偏估计，
			- 则基于完全充分统计量T的无偏估计量h(T)，为参数g(\theta)的唯一最优无偏估计（UMVUE），
	- 求解
		- 基本思路为寻找L-S定理所需要的条件，即充分性和无偏性，
		- 比较法
		  collapsed:: true
			- 基于充分统计量T，
			  collapsed:: true
				- （判断统计量T是否为完备族），
				- 求解充分统计量T的期望ET，
				- 比较ET与需要求解的参数\theta（或参数的函数h(\theta)），
				- 若可写为$ET = f[h(\theta)]$，且f为一一对应函数，
				- 则可解得$E[f^{-1}(T)] = f^{-1}(f[h(\theta)]) = h(\theta)$，
				- 因此，由L-S定理可知$f^{-1}(T)$为h(\theta)的UMVUE，
			- 基于最大似然估计量W，
			  collapsed:: true
				- （判断统计量T是否为完备族），
				- 一般mle估计量W为充分统计量T的函数，
				  collapsed:: true
					- 若W不是T的函数，则应基于充分统计量T寻找，
				- 由mle的不变性，可知需要求解的参数的函数h(\theta)的mle为h(W)，
				- 求解h(W)的期望E[h(W)]，
				- 比较E[h(W)]与需要求解的参数的函数h(\theta)，
			- 求解充分统计量的函数h(T)，
			  collapsed:: true
				- 对于较复杂的参数，可以设无偏估计量为充分统计量的某未知函数h(T)，
				- 再利用数学分析方法分析期望算式，
				- 一般求和号\sum和积分号\int是不能运算的，因此主要为对求和（积分）函数进行分析，
				- 离散：$\sum \limits _{t = 0}^{+\infty}h(T)P(T = t) = g(\theta)$，一般采用级数展开的方法分析，
				  collapsed:: true
					- 示例：设X_{i} \sim P(\lambda)，求\lambda^{r}的UMVUE，
					- ![image.png](../assets/image_1668503150496_0.png)，
					- ![image.png](../assets/image_1668503300969_0.png)，
				- 连续：$\int_{S_{T}}h(T)f_{T}(t)dt = g(\theta)$，一般通过（对参数）求导等方法分析，
				  collapsed:: true
					- 示例：设X_{i} \sim Exp(\lambda)，求$e^{- \lambda c}$的UMVUE，
					- ![image.png](../assets/image_1668505348592_0.png)，
				- 连续：分布的*支集*依赖于\theta，
				  collapsed:: true
					- 若分布的支集依赖于\theta，且密度函数f_{X}中的\theta，x可以分离，
					- 则可分离等式中的\theta与x，写为$\int_{0}^{\theta}g(X)f_{1}(x)dx = h(\theta)f_{2}(\theta)$，
					  collapsed:: true
						- 由于左侧为对x积分，因此\theta的函数可以从积分号内提出，
					- 两侧对*参数θ*求导，可得$g(\theta)f_{1}(\theta) = h'(\theta)f'_{2}(\theta)$，
					- 因此，可知*函数g*的表达式应为$g(\theta) = \dfrac{h'(\theta)f'_{2}(\theta)}{f_{1}(\theta)}$，
					- 所以，UMVUE为$g(X) = \dfrac{h'(X)f'_{2}(X)}{f_{1}(X)}$，
		- R-B定理法
		  collapsed:: true
			- 充分统计量T
			  collapsed:: true
				- R-B定理的基本思路为，基于无偏估计量W的充分统计量T的函数为UMVUE，
				- 因此，应先依据分布族的形式，寻找充分统计量T，
				- 然后应求出T的分布（数字特征），
			- （完备族的证明）
			- 无偏估计量W
			  collapsed:: true
				- R-B定理对无偏估计量没有严格要求，
				- 因此，应选取易于计算的无偏估计量，
				- 一般基于少量样本X_{1}，X_{2}，X_{3}…设置无偏估计量，
			- 条件期望的求解
			  collapsed:: true
				- 按照R-B定理和L-S定理，条件期望E(W | T) = h(T)为UMVUE，
				  collapsed:: true
					- 无偏估计量W一般与充分统计量T相关，因此其联合分布f(W, T)一般较难直接求解，
					- 如果可以根据T和W的关系，将条件概率转化为无条件概率，则可以简化运算，
				- 离散情况$\sum \limits _{S_{W|T}}wP(W | T)$，
				  collapsed:: true
					- 可尝试拆分充分统计量T，转为无条件概率，
					- 即$P(W | T) = \dfrac{P(W, T)}{P(T)} = \dfrac{P(W = w, T = t)}{P(T = t)} = \dfrac{P(W = w, T' = t - w)}{P(T = t)} = \dfrac{P(W = w)P(T' = t - w)}{P(T = t)}$，
				- 连续情况$E(W | T) = \int_{S_{W|T}}wf(W | T)dw = \int_{S_{W|T}}w\dfrac{f(W, T)}{f(T)}dw$，
				  collapsed:: true
					- 一般充分统计量难以直接拆分，
					- 可以尝试利用Basu定理，将其转化为无条件概率，
						- 位置族
						  collapsed:: true
							- X_{i} \sim N(\mu, 1)，求P(X < c)的UMVUE，
							- 无偏估计量为$Y = \begin{cases}  1 & X_{1} < c \\ 0 & 其它 \end{cases}$，
							- 条件期望：$E(Y|T) = P(X_{1} < c | \overline{X} = \bar{x})$,
							- 化简：$P(X_{1} - \overline{X} < c - \bar{x} | \overline{X} = \bar{x})$
							- Basu定理：$P(X_{1} - \overline{X} < c - \bar{x})$，
							- 由$X_{1} - \overline{X} \sim N(0, \frac{n - 1}{n})$，可得$E(Y|T) = \Phi[\sqrt{\frac{n}{n - 1}}(c - \bar{x})]$，
						- 尺度族
						  collapsed:: true
							- X_{i} \sim Exp(\lambda)，求P(X < c)的UMVUE，
							- 无偏估计量为$Y = \begin{cases}  1 & X_{1} < c \\ 0 & 其它 \end{cases}$，
							- 条件期望：$E(Y|T) = P(X_{1} < c | \sum{X} = t)$,
							- 化简：$P(\dfrac{X_{1}}{\sum{X}} < \dfrac{c}{t} | \sum{X} = t)$
							- Basu定理：$P(\dfrac{X_{1}}{\sum{X}} < \dfrac{c}{t})$，
							- 由$\dfrac{X_{1}}{\sum{X}} \sim \Beta(1, {n - 1})$，可得$E(Y|T) = 1 - (1 - \frac{c}{t})^{n - 1}$，
			- 技巧
			  collapsed:: true
				- 充分统计量的设置
				  collapsed:: true
					- 理论上，充分统计量应包括“所有”在题目中出现的样本，
					- 例如，求$P(\sum \limits _{i= 1}^{n}X_{i} > X_{i + 1})$的UMVUE时，充分统计量应设为$\sum \limits _{i= 1}^{n + 1}X_{i}$，
				- 条件概率在不同情况下的取值不同，
				  collapsed:: true
					- 应区分不同情况（事件），逐个计算对应的概率，
					- 一般应以*充分统计量*的取值为主要分段标准，再分析其它变量的情况，
				- 示例
				  collapsed:: true
					- 对于$X_{i} \sim b(1, p)$，求$P(\sum \limits _{i= 1}^{n}X_{i} > X_{n + 1})$的UMVUE，
					- 充分统计量
					  collapsed:: true
						- 设充分统计量$T = \sum \limits _{i= 1}^{n + 1}X_{i}$，
						- 由二项分布的可加性，可知$T \sim b(n + 1, p)$，
					- 无偏估计量
					  collapsed:: true
						- 设无偏估计量$W = \begin{cases}  1 & P(T=\sum \limits _{i= 1}^{n + 1}X_{i} > 2X_{n + 1}) \\ 0 & 其它 \end{cases}$，
					- 求解条件期望
					  collapsed:: true
						- 由条件期望的定义，$\varphi(T) = E(W | T) = 1 \cdot P(W | T) + 0 = P(W | T)$，
						- 由条件概率的定义，$P(W | T) = \dfrac{P(W, T)}{P(T)} = \dfrac{P(\sum \limits _{i= 1}^{n + 1}X_{i} > 2X_{n + 1}, \sum \limits _{i= 1}^{n + 1}X_{i} = t)}{P(\sum \limits _{i= 1}^{n + 1}X_{i} = t)}$
						  id:: 62ba5cef-5217-4bd0-902a-863f7d9ef8f3
						- 按照充分统计量T的值分段讨论，
						  collapsed:: true
							- T = 0时，一定有X_{n + 1} = 0；此时P(T > 2X_{n + 1}) = 0，即P(W | T) = 0，
							- T = 1或2时，
							  collapsed:: true
								- X_{n + 1} = 1时，仍有P(T > 2X_{n + 1}) = 0，即P(W | T) = 0，
								- X_{n + 1} = 0时，
								  collapsed:: true
									- $P(W | T) = \dfrac{P(\sum \limits _{i= 1}^{n + 1}X_{i} > 0, \sum \limits _{i= 1}^{n + 1}X_{i} = t)P(X_{n + 1} = 0)}{P(\sum \limits _{i= 1}^{n + 1}X_{i} = t)} = \dfrac{{n \choose t}{\theta}^{t}{(1 - \theta)}^{n - t}(1 - \theta)}{{n + 1 \choose t}{\theta}^{t}{(1 - \theta)}^{n + 1 - t}} = \dfrac{n \choose t}{n + 1 \choose t}$，
							- T ≥ 3时，
							  collapsed:: true
								- 无论X_{n + 1} = 1或0，P(T > 2X_{n + 1})都是必然事件，即P(T > 2X_{n + 1}) = 1，
								- 此时条件期望$P(W | T) = \dfrac{P(\sum \limits _{i= 1}^{n + 1}X_{i} > 2X_{n + 1}, \sum \limits _{i= 1}^{n + 1}X_{i} = t)}{P(\sum \limits _{i= 1}^{n + 1}X_{i} = t)} = \dfrac{P(\sum \limits _{i= 1}^{n + 1}X_{i} = t)}{P(\sum \limits _{i= 1}^{n + 1}X_{i} = t)} = 1$，
					- 综上所述，UMVUE为$\begin{cases}  0 & T(\sum \limits _{i= 1}^{n + 1}X_{i}) = 0 \\ \dfrac{n + 1 - T}{n + 1} & T(\sum \limits _{i= 1}^{n + 1}X_{i}) = 1,2 \\ 1 & T(\sum \limits _{i= 1}^{n + 1}X_{i}) \geq 3 \end{cases}$，
- @概率密度函数的核估计（kernel）
  collapsed:: true
	- 概率密度函数$f(x) = \dfrac{1}{nh_{n}}\sum\limits_{i = 1}^{n}K(\dfrac{x - X_{i}}{h_{n}})$，
		- f(x)为密度函数，
		- h_{n}为区间宽度，n为区间个数，
		- X_{i}为样本（值），
		- K(x)为核函数，一般为某种密度函数，但其需要满足的条件不完全等同于密度函数，
	- 性质
-
- [[数理统计]]
-